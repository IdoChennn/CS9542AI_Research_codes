{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T23:01:37.360490284Z",
     "start_time": "2023-11-30T23:01:37.315862398Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T23:01:38.091059527Z",
     "start_time": "2023-11-30T23:01:38.082807070Z"
    }
   },
   "id": "a482ff0607bd7034"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performing Federated Learning Where each client has the entire dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786efaa8afc5c24"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Training round 1 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.5856, Accuracy: 64.86%\n",
      "Epoch 2, Loss: 0.7232, Accuracy: 66.14%\n",
      "Epoch 3, Loss: 0.6062, Accuracy: 66.31%\n",
      "Epoch 4, Loss: 0.6141, Accuracy: 66.51%\n",
      "Epoch 5, Loss: 0.7048, Accuracy: 66.56%\n",
      "Epoch 6, Loss: 0.7150, Accuracy: 66.58%\n",
      "Epoch 7, Loss: 0.6249, Accuracy: 66.70%\n",
      "Epoch 8, Loss: 0.6362, Accuracy: 66.61%\n",
      "Epoch 9, Loss: 0.6280, Accuracy: 66.77%\n",
      "Epoch 10, Loss: 0.6466, Accuracy: 66.75%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6115, Accuracy: 64.57%\n",
      "Epoch 2, Loss: 0.5295, Accuracy: 66.17%\n",
      "Epoch 3, Loss: 0.6913, Accuracy: 66.39%\n",
      "Epoch 4, Loss: 0.6543, Accuracy: 66.39%\n",
      "Epoch 5, Loss: 0.6540, Accuracy: 66.51%\n",
      "Epoch 6, Loss: 0.8747, Accuracy: 66.55%\n",
      "Epoch 7, Loss: 0.7932, Accuracy: 66.65%\n",
      "Epoch 8, Loss: 0.7982, Accuracy: 66.77%\n",
      "Epoch 9, Loss: 0.6679, Accuracy: 66.75%\n",
      "Epoch 10, Loss: 0.7038, Accuracy: 66.81%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.6132, Accuracy: 65.33%\n",
      "Epoch 2, Loss: 0.8327, Accuracy: 66.11%\n",
      "Epoch 3, Loss: 0.7514, Accuracy: 66.40%\n",
      "Epoch 4, Loss: 0.6254, Accuracy: 66.39%\n",
      "Epoch 5, Loss: 0.7630, Accuracy: 66.55%\n",
      "Epoch 6, Loss: 0.6024, Accuracy: 66.61%\n",
      "Epoch 7, Loss: 0.5932, Accuracy: 66.70%\n",
      "Epoch 8, Loss: 0.5628, Accuracy: 66.65%\n",
      "Epoch 9, Loss: 0.5871, Accuracy: 66.74%\n",
      "Epoch 10, Loss: 0.6910, Accuracy: 66.76%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.6876, Accuracy: 65.40%\n",
      "Epoch 2, Loss: 0.7119, Accuracy: 66.19%\n",
      "Epoch 3, Loss: 0.6218, Accuracy: 66.28%\n",
      "Epoch 4, Loss: 0.6081, Accuracy: 66.36%\n",
      "Epoch 5, Loss: 0.6251, Accuracy: 66.51%\n",
      "Epoch 6, Loss: 0.7273, Accuracy: 66.59%\n",
      "Epoch 7, Loss: 0.6807, Accuracy: 66.66%\n",
      "Epoch 8, Loss: 0.5337, Accuracy: 66.61%\n",
      "Epoch 9, Loss: 0.6246, Accuracy: 66.74%\n",
      "Epoch 10, Loss: 0.6861, Accuracy: 66.68%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.6578, Accuracy: 65.21%\n",
      "Epoch 2, Loss: 0.6648, Accuracy: 66.25%\n",
      "Epoch 3, Loss: 0.5711, Accuracy: 66.30%\n",
      "Epoch 4, Loss: 0.5740, Accuracy: 66.38%\n",
      "Epoch 5, Loss: 0.6322, Accuracy: 66.51%\n",
      "Epoch 6, Loss: 0.6576, Accuracy: 66.65%\n",
      "Epoch 7, Loss: 0.6475, Accuracy: 66.64%\n",
      "Epoch 8, Loss: 0.6501, Accuracy: 66.77%\n",
      "Epoch 9, Loss: 0.7768, Accuracy: 66.77%\n",
      "Epoch 10, Loss: 0.7561, Accuracy: 66.81%\n",
      "\n",
      "\n",
      "=========== Training round 2 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.6187, Accuracy: 66.76%\n",
      "Epoch 2, Loss: 0.6721, Accuracy: 66.84%\n",
      "Epoch 3, Loss: 0.6825, Accuracy: 66.82%\n",
      "Epoch 4, Loss: 0.7536, Accuracy: 66.82%\n",
      "Epoch 5, Loss: 0.5859, Accuracy: 66.87%\n",
      "Epoch 6, Loss: 0.6375, Accuracy: 66.83%\n",
      "Epoch 7, Loss: 0.6419, Accuracy: 66.91%\n",
      "Epoch 8, Loss: 0.6861, Accuracy: 66.84%\n",
      "Epoch 9, Loss: 0.5577, Accuracy: 66.94%\n",
      "Epoch 10, Loss: 0.6402, Accuracy: 66.66%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.7064, Accuracy: 66.74%\n",
      "Epoch 2, Loss: 0.6835, Accuracy: 66.81%\n",
      "Epoch 3, Loss: 0.7255, Accuracy: 66.83%\n",
      "Epoch 4, Loss: 0.6735, Accuracy: 66.84%\n",
      "Epoch 5, Loss: 0.5887, Accuracy: 66.89%\n",
      "Epoch 6, Loss: 0.7579, Accuracy: 66.72%\n",
      "Epoch 7, Loss: 0.6127, Accuracy: 66.94%\n",
      "Epoch 8, Loss: 0.6607, Accuracy: 66.92%\n",
      "Epoch 9, Loss: 0.6585, Accuracy: 66.92%\n",
      "Epoch 10, Loss: 0.7584, Accuracy: 66.85%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.7073, Accuracy: 66.77%\n",
      "Epoch 2, Loss: 0.6409, Accuracy: 66.76%\n",
      "Epoch 3, Loss: 0.5549, Accuracy: 66.84%\n",
      "Epoch 4, Loss: 0.5799, Accuracy: 66.82%\n",
      "Epoch 5, Loss: 0.6857, Accuracy: 66.83%\n",
      "Epoch 6, Loss: 0.6385, Accuracy: 66.90%\n",
      "Epoch 7, Loss: 0.6174, Accuracy: 66.91%\n",
      "Epoch 8, Loss: 0.5535, Accuracy: 66.89%\n",
      "Epoch 9, Loss: 0.7642, Accuracy: 66.99%\n",
      "Epoch 10, Loss: 0.6313, Accuracy: 66.97%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.6513, Accuracy: 66.81%\n",
      "Epoch 2, Loss: 0.6632, Accuracy: 66.83%\n",
      "Epoch 3, Loss: 0.6885, Accuracy: 66.77%\n",
      "Epoch 4, Loss: 0.6028, Accuracy: 66.83%\n",
      "Epoch 5, Loss: 0.6836, Accuracy: 66.86%\n",
      "Epoch 6, Loss: 0.7460, Accuracy: 66.68%\n",
      "Epoch 7, Loss: 0.6499, Accuracy: 66.89%\n",
      "Epoch 8, Loss: 0.6354, Accuracy: 66.88%\n",
      "Epoch 9, Loss: 0.7940, Accuracy: 66.88%\n",
      "Epoch 10, Loss: 0.7503, Accuracy: 66.97%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.7512, Accuracy: 66.84%\n",
      "Epoch 2, Loss: 0.5835, Accuracy: 66.81%\n",
      "Epoch 3, Loss: 0.6255, Accuracy: 66.81%\n",
      "Epoch 4, Loss: 0.6592, Accuracy: 66.86%\n",
      "Epoch 5, Loss: 0.6369, Accuracy: 66.75%\n",
      "Epoch 6, Loss: 0.8400, Accuracy: 66.88%\n",
      "Epoch 7, Loss: 0.7263, Accuracy: 66.87%\n",
      "Epoch 8, Loss: 0.9403, Accuracy: 66.94%\n",
      "Epoch 9, Loss: 0.5463, Accuracy: 66.92%\n",
      "Epoch 10, Loss: 0.6582, Accuracy: 66.91%\n",
      "\n",
      "\n",
      "=========== Training round 3 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.6980, Accuracy: 66.94%\n",
      "Epoch 2, Loss: 0.5949, Accuracy: 66.96%\n",
      "Epoch 3, Loss: 0.6369, Accuracy: 66.94%\n",
      "Epoch 4, Loss: 0.7413, Accuracy: 66.92%\n",
      "Epoch 5, Loss: 0.5376, Accuracy: 67.04%\n",
      "Epoch 6, Loss: 0.5968, Accuracy: 67.00%\n",
      "Epoch 7, Loss: 0.6724, Accuracy: 66.96%\n",
      "Epoch 8, Loss: 0.6284, Accuracy: 66.88%\n",
      "Epoch 9, Loss: 0.6054, Accuracy: 66.99%\n",
      "Epoch 10, Loss: 0.6959, Accuracy: 66.98%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.5184, Accuracy: 66.87%\n",
      "Epoch 2, Loss: 0.6723, Accuracy: 66.93%\n",
      "Epoch 3, Loss: 0.6183, Accuracy: 66.91%\n",
      "Epoch 4, Loss: 0.6870, Accuracy: 66.92%\n",
      "Epoch 5, Loss: 0.6000, Accuracy: 67.02%\n",
      "Epoch 6, Loss: 0.6405, Accuracy: 66.93%\n",
      "Epoch 7, Loss: 0.6216, Accuracy: 66.99%\n",
      "Epoch 8, Loss: 0.6547, Accuracy: 66.87%\n",
      "Epoch 9, Loss: 0.6687, Accuracy: 67.03%\n",
      "Epoch 10, Loss: 0.7634, Accuracy: 67.06%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.7284, Accuracy: 66.99%\n",
      "Epoch 2, Loss: 0.7691, Accuracy: 66.88%\n",
      "Epoch 3, Loss: 0.6951, Accuracy: 66.98%\n",
      "Epoch 4, Loss: 0.7010, Accuracy: 66.92%\n",
      "Epoch 5, Loss: 0.6325, Accuracy: 66.88%\n",
      "Epoch 6, Loss: 0.6475, Accuracy: 66.96%\n",
      "Epoch 7, Loss: 0.7359, Accuracy: 67.04%\n",
      "Epoch 8, Loss: 0.6484, Accuracy: 67.01%\n",
      "Epoch 9, Loss: 0.7665, Accuracy: 66.85%\n",
      "Epoch 10, Loss: 0.6850, Accuracy: 66.89%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.6372, Accuracy: 66.97%\n",
      "Epoch 2, Loss: 0.6368, Accuracy: 66.91%\n",
      "Epoch 3, Loss: 0.7036, Accuracy: 66.97%\n",
      "Epoch 4, Loss: 0.6597, Accuracy: 66.94%\n",
      "Epoch 5, Loss: 0.6759, Accuracy: 66.89%\n",
      "Epoch 6, Loss: 0.7050, Accuracy: 66.91%\n",
      "Epoch 7, Loss: 0.6592, Accuracy: 66.95%\n",
      "Epoch 8, Loss: 0.7073, Accuracy: 67.04%\n",
      "Epoch 9, Loss: 0.6967, Accuracy: 66.92%\n",
      "Epoch 10, Loss: 0.5781, Accuracy: 67.00%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.6714, Accuracy: 66.91%\n",
      "Epoch 2, Loss: 0.6658, Accuracy: 66.93%\n",
      "Epoch 3, Loss: 0.6580, Accuracy: 66.87%\n",
      "Epoch 4, Loss: 0.6930, Accuracy: 66.96%\n",
      "Epoch 5, Loss: 0.6792, Accuracy: 67.01%\n",
      "Epoch 6, Loss: 0.5942, Accuracy: 66.98%\n",
      "Epoch 7, Loss: 0.5923, Accuracy: 67.01%\n",
      "Epoch 8, Loss: 0.5939, Accuracy: 67.04%\n",
      "Epoch 9, Loss: 0.7823, Accuracy: 66.90%\n",
      "Epoch 10, Loss: 0.7536, Accuracy: 67.04%\n",
      "\n",
      "\n",
      "=========== Training round 4 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.7213, Accuracy: 66.98%\n",
      "Epoch 2, Loss: 0.5770, Accuracy: 66.93%\n",
      "Epoch 3, Loss: 0.7201, Accuracy: 66.98%\n",
      "Epoch 4, Loss: 0.6969, Accuracy: 67.05%\n",
      "Epoch 5, Loss: 0.7129, Accuracy: 66.98%\n",
      "Epoch 6, Loss: 0.8943, Accuracy: 66.94%\n",
      "Epoch 7, Loss: 0.6764, Accuracy: 67.06%\n",
      "Epoch 8, Loss: 0.6945, Accuracy: 67.01%\n",
      "Epoch 9, Loss: 0.8084, Accuracy: 67.08%\n",
      "Epoch 10, Loss: 0.6490, Accuracy: 67.00%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6511, Accuracy: 66.72%\n",
      "Epoch 2, Loss: 0.6969, Accuracy: 66.87%\n",
      "Epoch 3, Loss: 0.6892, Accuracy: 67.08%\n",
      "Epoch 4, Loss: 0.6794, Accuracy: 67.01%\n",
      "Epoch 5, Loss: 0.5725, Accuracy: 67.06%\n",
      "Epoch 6, Loss: 0.6566, Accuracy: 66.95%\n",
      "Epoch 7, Loss: 0.7869, Accuracy: 67.05%\n",
      "Epoch 8, Loss: 0.6642, Accuracy: 67.04%\n",
      "Epoch 9, Loss: 0.6661, Accuracy: 66.99%\n",
      "Epoch 10, Loss: 0.6894, Accuracy: 66.96%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.6414, Accuracy: 66.82%\n",
      "Epoch 2, Loss: 0.7345, Accuracy: 67.04%\n",
      "Epoch 3, Loss: 0.6314, Accuracy: 67.04%\n",
      "Epoch 4, Loss: 0.6750, Accuracy: 66.98%\n",
      "Epoch 5, Loss: 0.6724, Accuracy: 66.87%\n",
      "Epoch 6, Loss: 0.6758, Accuracy: 66.86%\n",
      "Epoch 7, Loss: 0.6199, Accuracy: 67.05%\n",
      "Epoch 8, Loss: 0.6014, Accuracy: 67.06%\n",
      "Epoch 9, Loss: 0.7344, Accuracy: 67.04%\n",
      "Epoch 10, Loss: 0.6281, Accuracy: 67.07%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.6382, Accuracy: 66.83%\n",
      "Epoch 2, Loss: 0.7595, Accuracy: 66.94%\n",
      "Epoch 3, Loss: 0.7010, Accuracy: 67.04%\n",
      "Epoch 4, Loss: 0.5796, Accuracy: 67.06%\n",
      "Epoch 5, Loss: 0.5667, Accuracy: 67.05%\n",
      "Epoch 6, Loss: 0.6283, Accuracy: 67.07%\n",
      "Epoch 7, Loss: 0.6730, Accuracy: 67.07%\n",
      "Epoch 8, Loss: 0.6108, Accuracy: 67.09%\n",
      "Epoch 9, Loss: 0.8590, Accuracy: 67.09%\n",
      "Epoch 10, Loss: 0.5902, Accuracy: 66.97%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.7055, Accuracy: 66.95%\n",
      "Epoch 2, Loss: 0.6885, Accuracy: 66.91%\n",
      "Epoch 3, Loss: 0.7028, Accuracy: 66.94%\n",
      "Epoch 4, Loss: 0.6419, Accuracy: 67.03%\n",
      "Epoch 5, Loss: 0.6408, Accuracy: 67.03%\n",
      "Epoch 6, Loss: 0.5751, Accuracy: 67.04%\n",
      "Epoch 7, Loss: 0.6415, Accuracy: 66.91%\n",
      "Epoch 8, Loss: 0.5944, Accuracy: 66.99%\n",
      "Epoch 9, Loss: 0.6773, Accuracy: 66.74%\n",
      "Epoch 10, Loss: 0.6168, Accuracy: 67.01%\n",
      "\n",
      "\n",
      "=========== Training round 5 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.5873, Accuracy: 67.06%\n",
      "Epoch 2, Loss: 0.6180, Accuracy: 67.08%\n",
      "Epoch 3, Loss: 0.8598, Accuracy: 67.10%\n",
      "Epoch 4, Loss: 0.7223, Accuracy: 66.94%\n",
      "Epoch 5, Loss: 0.6270, Accuracy: 66.93%\n",
      "Epoch 6, Loss: 0.6539, Accuracy: 66.98%\n",
      "Epoch 7, Loss: 0.6207, Accuracy: 67.04%\n",
      "Epoch 8, Loss: 0.6519, Accuracy: 67.02%\n",
      "Epoch 9, Loss: 0.7269, Accuracy: 67.13%\n",
      "Epoch 10, Loss: 0.5912, Accuracy: 67.11%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6508, Accuracy: 66.99%\n",
      "Epoch 2, Loss: 0.6437, Accuracy: 66.90%\n",
      "Epoch 3, Loss: 0.5972, Accuracy: 67.10%\n",
      "Epoch 4, Loss: 0.8049, Accuracy: 66.96%\n",
      "Epoch 5, Loss: 0.5718, Accuracy: 67.06%\n",
      "Epoch 6, Loss: 0.7290, Accuracy: 67.02%\n",
      "Epoch 7, Loss: 0.7213, Accuracy: 66.96%\n",
      "Epoch 8, Loss: 0.7334, Accuracy: 67.10%\n",
      "Epoch 9, Loss: 0.7189, Accuracy: 67.09%\n",
      "Epoch 10, Loss: 0.5176, Accuracy: 67.06%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.6893, Accuracy: 67.00%\n",
      "Epoch 2, Loss: 0.6794, Accuracy: 67.04%\n",
      "Epoch 3, Loss: 0.5577, Accuracy: 67.07%\n",
      "Epoch 4, Loss: 0.7664, Accuracy: 67.08%\n",
      "Epoch 5, Loss: 0.6452, Accuracy: 67.03%\n",
      "Epoch 6, Loss: 0.7752, Accuracy: 67.08%\n",
      "Epoch 7, Loss: 0.7023, Accuracy: 66.98%\n",
      "Epoch 8, Loss: 0.5923, Accuracy: 67.03%\n",
      "Epoch 9, Loss: 0.7339, Accuracy: 67.10%\n",
      "Epoch 10, Loss: 0.6435, Accuracy: 66.88%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.5652, Accuracy: 67.07%\n",
      "Epoch 2, Loss: 0.6226, Accuracy: 67.05%\n",
      "Epoch 3, Loss: 0.7069, Accuracy: 66.99%\n",
      "Epoch 4, Loss: 0.6768, Accuracy: 67.08%\n",
      "Epoch 5, Loss: 0.6209, Accuracy: 67.00%\n",
      "Epoch 6, Loss: 0.6638, Accuracy: 67.13%\n",
      "Epoch 7, Loss: 0.6299, Accuracy: 66.98%\n",
      "Epoch 8, Loss: 0.6566, Accuracy: 67.07%\n",
      "Epoch 9, Loss: 0.6892, Accuracy: 67.11%\n",
      "Epoch 10, Loss: 0.6338, Accuracy: 67.03%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.6179, Accuracy: 66.98%\n",
      "Epoch 2, Loss: 0.6627, Accuracy: 67.10%\n",
      "Epoch 3, Loss: 0.7976, Accuracy: 66.87%\n",
      "Epoch 4, Loss: 0.6673, Accuracy: 67.05%\n",
      "Epoch 5, Loss: 0.7185, Accuracy: 67.12%\n",
      "Epoch 6, Loss: 0.8062, Accuracy: 67.01%\n",
      "Epoch 7, Loss: 0.7380, Accuracy: 67.03%\n",
      "Epoch 8, Loss: 0.6366, Accuracy: 67.03%\n",
      "Epoch 9, Loss: 0.6451, Accuracy: 67.11%\n",
      "Epoch 10, Loss: 0.6536, Accuracy: 67.08%\n"
     ]
    }
   ],
   "source": [
    "myGPU = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def read_data():\n",
    "    # i want to read the data that every column are features from the csv file, and store the features in a tensor\n",
    "    # and the labels in a tensor\n",
    "    # i want to return a list of tensors, each tensor is a feature, and a tensor of labels\n",
    "    \n",
    "    # read the csv file\n",
    "    df = pd.read_csv('dataset/covid_x_csv_classification.csv')\n",
    "    label_df = pd.read_csv('dataset/covid_y_classification.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_sampled = df.sample(frac=0.1, random_state=42)\n",
    "    label_df_sampled = label_df.loc[df_sampled.index]\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    label_df_sampled = encoder.fit_transform(label_df_sampled.values.ravel())\n",
    "\n",
    "    features_tensor = torch.tensor(df_sampled.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    labels_tensor = torch.tensor(label_df_sampled, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    return features_tensor, labels_tensor\n",
    "\n",
    "X, y = read_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train.to(myGPU), y_train.to(myGPU))\n",
    "test_dataset = TensorDataset(X_test.to(myGPU), y_test.to(myGPU))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "def client_training(global_model):\n",
    "    \n",
    "    local_model = deepcopy(global_model).to(myGPU)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        loss = 0.0\n",
    "        local_model.train()\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(myGPU), data[1].to(myGPU)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        local_model.eval()\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = local_model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, Accuracy: {(correct / total) * 100:.2f}%')\n",
    "    return local_model\n",
    "\n",
    "def model_aggregate(clients_models):\n",
    "    aggregated_state = {}\n",
    "    clients_model_list = []\n",
    "    for models in clients_models:\n",
    "        clients_model_list.append(models.state_dict())\n",
    "        \n",
    "    for key in global_model.state_dict().keys():\n",
    "        tensors_to_aggregate = []\n",
    "        for client_state in clients_model_list:\n",
    "            client_tensor = client_state[key]\n",
    "            tensors_to_aggregate.append(client_tensor)\n",
    "\n",
    "        ### Performing FedAvg ###\n",
    "        stacked_tensors = torch.stack(tensors_to_aggregate, dim=0)\n",
    "        mean_tensor = torch.mean(stacked_tensors, dim=0)\n",
    "\n",
    "        aggregated_state[key] = mean_tensor\n",
    "\n",
    "    # Update the global model's weights with the aggregated weights\n",
    "    global_model.load_state_dict(aggregated_state)\n",
    "    return global_model\n",
    "\n",
    "global_model = Net(30, 4).to(myGPU)\n",
    "\n",
    "total_training_rounds = 5\n",
    "\n",
    "clients_number = 5\n",
    "\n",
    "\n",
    "\n",
    "for i in range(total_training_rounds):\n",
    "    print(f\"=========== Training round {i+1} ===========\")\n",
    "    clients_models = []\n",
    "    for i in range(clients_number):\n",
    "        print(f\"Training client {i+1}\")\n",
    "        clients_models.append(client_training(global_model))\n",
    "        print(\"\\n\")\n",
    "    # aggregate the models\n",
    "    global_model = model_aggregate(clients_models)\n",
    "print(\"End of Training\")\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:50:34.393253354Z",
     "start_time": "2023-11-30T22:47:53.413639522Z"
    }
   },
   "id": "a407d556d5b82391"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performing Federated Training Where each Client has its own part of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7361fcba509e11b8"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yche2692/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "myGPU = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def read_data():\n",
    "    # Read the CSV files\n",
    "    df = pd.read_csv('dataset/covid_x_csv_classification.csv')\n",
    "    label_df = pd.read_csv('dataset/covid_y_classification.csv')\n",
    "\n",
    "    # Sample 10% of the data\n",
    "    df_sampled = df.sample(frac=1, random_state=42)\n",
    "    label_df_sampled = label_df.loc[df_sampled.index]\n",
    "\n",
    "    # Label encoding\n",
    "    encoder = LabelEncoder()\n",
    "    label_df_sampled = encoder.fit_transform(label_df_sampled.values.ravel())\n",
    "\n",
    "    # Concatenate features and labels\n",
    "    combined_df = pd.concat([df_sampled, pd.DataFrame(label_df_sampled, index=df_sampled.index, columns=['Label'])], axis=1)\n",
    "\n",
    "    # Shuffle the combined DataFrame\n",
    "    combined_df_shuffled = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Split the DataFrame into 5 chunks\n",
    "    chunks = np.array_split(combined_df_shuffled, 5)\n",
    "\n",
    "    # Separate features and labels for each chunk\n",
    "    features_chunks = [torch.tensor(chunk.iloc[:, :-1].values, dtype=torch.float32) for chunk in chunks]\n",
    "    labels_chunks = [torch.tensor(chunk.iloc[:, -1].values, dtype=torch.long) for chunk in chunks]\n",
    "\n",
    "    return features_chunks, labels_chunks\n",
    "\n",
    "# Usage\n",
    "X, y = read_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:53:09.134294388Z",
     "start_time": "2023-11-30T22:53:06.070945908Z"
    }
   },
   "id": "20d62f89053f8a35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data partitioning to let each client has its own distinctive data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab9ffce9a746a536"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "client_train_dataloader = []\n",
    "client_test_dataloader = []\n",
    "\n",
    "for index in range(len(X)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[index], y[index], test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train.to(myGPU), y_train.to(myGPU))\n",
    "    test_dataset = TensorDataset(X_test.to(myGPU), y_test.to(myGPU))\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
    "    client_train_dataloader.append(train_loader)\n",
    "    client_test_dataloader.append(test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:53:11.201238778Z",
     "start_time": "2023-11-30T22:53:11.147440225Z"
    }
   },
   "id": "aec1e52b8e3235e5"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Training round 1 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.7867, Accuracy: 65.88%\n",
      "Epoch 2, Loss: 0.7690, Accuracy: 66.31%\n",
      "Epoch 3, Loss: 0.9238, Accuracy: 66.33%\n",
      "Epoch 4, Loss: 0.9973, Accuracy: 66.43%\n",
      "Epoch 5, Loss: 0.9041, Accuracy: 66.49%\n",
      "Epoch 6, Loss: 0.6180, Accuracy: 66.50%\n",
      "Epoch 7, Loss: 0.6846, Accuracy: 66.67%\n",
      "Epoch 8, Loss: 0.5848, Accuracy: 66.60%\n",
      "Epoch 9, Loss: 0.5273, Accuracy: 66.62%\n",
      "Epoch 10, Loss: 0.7130, Accuracy: 66.71%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6233, Accuracy: 66.09%\n",
      "Epoch 2, Loss: 0.5985, Accuracy: 66.52%\n",
      "Epoch 3, Loss: 0.5688, Accuracy: 66.65%\n",
      "Epoch 4, Loss: 0.6054, Accuracy: 66.75%\n",
      "Epoch 5, Loss: 0.5648, Accuracy: 66.72%\n",
      "Epoch 6, Loss: 0.8392, Accuracy: 66.83%\n",
      "Epoch 7, Loss: 0.6011, Accuracy: 66.85%\n",
      "Epoch 8, Loss: 0.6707, Accuracy: 66.94%\n",
      "Epoch 9, Loss: 0.6771, Accuracy: 66.90%\n",
      "Epoch 10, Loss: 0.8407, Accuracy: 66.95%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.5803, Accuracy: 65.63%\n",
      "Epoch 2, Loss: 0.5773, Accuracy: 66.20%\n",
      "Epoch 3, Loss: 0.5929, Accuracy: 66.33%\n",
      "Epoch 4, Loss: 0.5726, Accuracy: 66.38%\n",
      "Epoch 5, Loss: 0.7551, Accuracy: 66.44%\n",
      "Epoch 6, Loss: 0.5707, Accuracy: 66.46%\n",
      "Epoch 7, Loss: 0.5965, Accuracy: 66.44%\n",
      "Epoch 8, Loss: 0.5499, Accuracy: 66.56%\n",
      "Epoch 9, Loss: 0.5663, Accuracy: 66.55%\n",
      "Epoch 10, Loss: 0.6389, Accuracy: 66.64%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.6578, Accuracy: 65.62%\n",
      "Epoch 2, Loss: 0.5772, Accuracy: 66.01%\n",
      "Epoch 3, Loss: 0.7595, Accuracy: 66.31%\n",
      "Epoch 4, Loss: 0.6441, Accuracy: 66.39%\n",
      "Epoch 5, Loss: 0.9834, Accuracy: 66.30%\n",
      "Epoch 6, Loss: 0.7317, Accuracy: 66.43%\n",
      "Epoch 7, Loss: 0.5655, Accuracy: 66.51%\n",
      "Epoch 8, Loss: 0.7593, Accuracy: 66.63%\n",
      "Epoch 9, Loss: 0.7434, Accuracy: 66.56%\n",
      "Epoch 10, Loss: 0.7150, Accuracy: 66.60%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.5612, Accuracy: 65.91%\n",
      "Epoch 2, Loss: 0.5778, Accuracy: 66.33%\n",
      "Epoch 3, Loss: 0.5745, Accuracy: 66.45%\n",
      "Epoch 4, Loss: 0.5955, Accuracy: 66.53%\n",
      "Epoch 5, Loss: 0.7189, Accuracy: 66.57%\n",
      "Epoch 6, Loss: 0.6970, Accuracy: 66.67%\n",
      "Epoch 7, Loss: 0.6422, Accuracy: 66.72%\n",
      "Epoch 8, Loss: 0.5486, Accuracy: 66.74%\n",
      "Epoch 9, Loss: 0.5448, Accuracy: 66.76%\n",
      "Epoch 10, Loss: 0.6781, Accuracy: 66.73%\n",
      "\n",
      "\n",
      "=========== Training round 2 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.7121, Accuracy: 66.67%\n",
      "Epoch 2, Loss: 0.5772, Accuracy: 66.74%\n",
      "Epoch 3, Loss: 0.5406, Accuracy: 66.70%\n",
      "Epoch 4, Loss: 0.7400, Accuracy: 66.70%\n",
      "Epoch 5, Loss: 0.6790, Accuracy: 66.79%\n",
      "Epoch 6, Loss: 0.5691, Accuracy: 66.76%\n",
      "Epoch 7, Loss: 0.6405, Accuracy: 66.80%\n",
      "Epoch 8, Loss: 0.7200, Accuracy: 66.77%\n",
      "Epoch 9, Loss: 0.7560, Accuracy: 66.77%\n",
      "Epoch 10, Loss: 0.5207, Accuracy: 66.79%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6353, Accuracy: 66.92%\n",
      "Epoch 2, Loss: 0.7791, Accuracy: 67.01%\n",
      "Epoch 3, Loss: 0.6972, Accuracy: 67.09%\n",
      "Epoch 4, Loss: 0.6781, Accuracy: 67.09%\n",
      "Epoch 5, Loss: 0.6687, Accuracy: 67.14%\n",
      "Epoch 6, Loss: 0.6181, Accuracy: 67.11%\n",
      "Epoch 7, Loss: 0.6936, Accuracy: 67.08%\n",
      "Epoch 8, Loss: 0.5987, Accuracy: 67.15%\n",
      "Epoch 9, Loss: 0.5921, Accuracy: 67.11%\n",
      "Epoch 10, Loss: 0.6229, Accuracy: 67.04%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.5832, Accuracy: 66.67%\n",
      "Epoch 2, Loss: 0.5672, Accuracy: 66.72%\n",
      "Epoch 3, Loss: 0.5854, Accuracy: 66.75%\n",
      "Epoch 4, Loss: 0.6126, Accuracy: 66.67%\n",
      "Epoch 5, Loss: 0.5738, Accuracy: 66.77%\n",
      "Epoch 6, Loss: 0.8073, Accuracy: 66.71%\n",
      "Epoch 7, Loss: 0.7571, Accuracy: 66.73%\n",
      "Epoch 8, Loss: 0.5299, Accuracy: 66.78%\n",
      "Epoch 9, Loss: 0.7042, Accuracy: 66.75%\n",
      "Epoch 10, Loss: 0.6749, Accuracy: 66.75%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.9531, Accuracy: 66.58%\n",
      "Epoch 2, Loss: 0.8445, Accuracy: 66.67%\n",
      "Epoch 3, Loss: 0.5691, Accuracy: 66.62%\n",
      "Epoch 4, Loss: 0.7307, Accuracy: 66.58%\n",
      "Epoch 5, Loss: 0.7281, Accuracy: 66.59%\n",
      "Epoch 6, Loss: 0.6510, Accuracy: 66.54%\n",
      "Epoch 7, Loss: 0.5168, Accuracy: 66.59%\n",
      "Epoch 8, Loss: 0.5668, Accuracy: 66.67%\n",
      "Epoch 9, Loss: 0.5871, Accuracy: 66.69%\n",
      "Epoch 10, Loss: 0.6298, Accuracy: 66.64%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.6345, Accuracy: 66.81%\n",
      "Epoch 2, Loss: 0.6396, Accuracy: 66.77%\n",
      "Epoch 3, Loss: 0.7363, Accuracy: 66.87%\n",
      "Epoch 4, Loss: 0.6638, Accuracy: 66.90%\n",
      "Epoch 5, Loss: 0.7214, Accuracy: 66.89%\n",
      "Epoch 6, Loss: 0.8414, Accuracy: 66.88%\n",
      "Epoch 7, Loss: 0.6277, Accuracy: 66.91%\n",
      "Epoch 8, Loss: 0.5858, Accuracy: 66.87%\n",
      "Epoch 9, Loss: 0.5592, Accuracy: 66.90%\n",
      "Epoch 10, Loss: 0.8557, Accuracy: 66.92%\n",
      "\n",
      "\n",
      "=========== Training round 3 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.6022, Accuracy: 66.89%\n",
      "Epoch 2, Loss: 0.7109, Accuracy: 66.91%\n",
      "Epoch 3, Loss: 0.6886, Accuracy: 66.88%\n",
      "Epoch 4, Loss: 0.5272, Accuracy: 66.89%\n",
      "Epoch 5, Loss: 0.6932, Accuracy: 66.89%\n",
      "Epoch 6, Loss: 0.5593, Accuracy: 66.87%\n",
      "Epoch 7, Loss: 0.7058, Accuracy: 66.94%\n",
      "Epoch 8, Loss: 0.5228, Accuracy: 66.83%\n",
      "Epoch 9, Loss: 1.0133, Accuracy: 66.91%\n",
      "Epoch 10, Loss: 0.6679, Accuracy: 66.90%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.5883, Accuracy: 67.15%\n",
      "Epoch 2, Loss: 0.6245, Accuracy: 67.11%\n",
      "Epoch 3, Loss: 0.6566, Accuracy: 67.07%\n",
      "Epoch 4, Loss: 0.5537, Accuracy: 67.19%\n",
      "Epoch 5, Loss: 0.7152, Accuracy: 67.16%\n",
      "Epoch 6, Loss: 0.6965, Accuracy: 67.12%\n",
      "Epoch 7, Loss: 0.6442, Accuracy: 67.16%\n",
      "Epoch 8, Loss: 0.7635, Accuracy: 67.22%\n",
      "Epoch 9, Loss: 0.8392, Accuracy: 67.19%\n",
      "Epoch 10, Loss: 0.6134, Accuracy: 67.05%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.5791, Accuracy: 66.75%\n",
      "Epoch 2, Loss: 0.5932, Accuracy: 66.72%\n",
      "Epoch 3, Loss: 0.6618, Accuracy: 66.78%\n",
      "Epoch 4, Loss: 0.5989, Accuracy: 66.74%\n",
      "Epoch 5, Loss: 0.5456, Accuracy: 66.73%\n",
      "Epoch 6, Loss: 0.7039, Accuracy: 66.76%\n",
      "Epoch 7, Loss: 0.5706, Accuracy: 66.75%\n",
      "Epoch 8, Loss: 0.6458, Accuracy: 66.76%\n",
      "Epoch 9, Loss: 0.6806, Accuracy: 66.77%\n",
      "Epoch 10, Loss: 0.6346, Accuracy: 66.79%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.7299, Accuracy: 66.68%\n",
      "Epoch 2, Loss: 0.6608, Accuracy: 66.63%\n",
      "Epoch 3, Loss: 0.6314, Accuracy: 66.66%\n",
      "Epoch 4, Loss: 0.7236, Accuracy: 66.70%\n",
      "Epoch 5, Loss: 0.6638, Accuracy: 66.60%\n",
      "Epoch 6, Loss: 0.5944, Accuracy: 66.66%\n",
      "Epoch 7, Loss: 0.6745, Accuracy: 66.65%\n",
      "Epoch 8, Loss: 0.7885, Accuracy: 66.66%\n",
      "Epoch 9, Loss: 0.6552, Accuracy: 66.67%\n",
      "Epoch 10, Loss: 0.6521, Accuracy: 66.61%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.5682, Accuracy: 67.01%\n",
      "Epoch 2, Loss: 0.7602, Accuracy: 66.89%\n",
      "Epoch 3, Loss: 0.6638, Accuracy: 66.94%\n",
      "Epoch 4, Loss: 0.9251, Accuracy: 66.94%\n",
      "Epoch 5, Loss: 0.4780, Accuracy: 66.89%\n",
      "Epoch 6, Loss: 0.5835, Accuracy: 66.91%\n",
      "Epoch 7, Loss: 0.6922, Accuracy: 67.01%\n",
      "Epoch 8, Loss: 0.7109, Accuracy: 66.93%\n",
      "Epoch 9, Loss: 0.6035, Accuracy: 66.96%\n",
      "Epoch 10, Loss: 0.6505, Accuracy: 66.94%\n",
      "\n",
      "\n",
      "=========== Training round 4 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.6941, Accuracy: 66.96%\n",
      "Epoch 2, Loss: 0.7755, Accuracy: 66.96%\n",
      "Epoch 3, Loss: 0.6431, Accuracy: 66.99%\n",
      "Epoch 4, Loss: 0.6566, Accuracy: 66.97%\n",
      "Epoch 5, Loss: 0.8368, Accuracy: 66.99%\n",
      "Epoch 6, Loss: 0.7733, Accuracy: 67.07%\n",
      "Epoch 7, Loss: 0.7056, Accuracy: 67.00%\n",
      "Epoch 8, Loss: 0.7437, Accuracy: 67.01%\n",
      "Epoch 9, Loss: 0.8429, Accuracy: 67.06%\n",
      "Epoch 10, Loss: 0.5175, Accuracy: 67.06%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.6906, Accuracy: 67.21%\n",
      "Epoch 2, Loss: 0.6841, Accuracy: 67.13%\n",
      "Epoch 3, Loss: 0.5730, Accuracy: 67.20%\n",
      "Epoch 4, Loss: 0.6743, Accuracy: 67.25%\n",
      "Epoch 5, Loss: 0.5341, Accuracy: 67.24%\n",
      "Epoch 6, Loss: 0.5993, Accuracy: 67.26%\n",
      "Epoch 7, Loss: 0.5781, Accuracy: 67.23%\n",
      "Epoch 8, Loss: 0.7142, Accuracy: 67.12%\n",
      "Epoch 9, Loss: 0.7925, Accuracy: 67.22%\n",
      "Epoch 10, Loss: 0.7309, Accuracy: 67.12%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.5940, Accuracy: 66.70%\n",
      "Epoch 2, Loss: 0.7654, Accuracy: 66.76%\n",
      "Epoch 3, Loss: 0.6447, Accuracy: 66.78%\n",
      "Epoch 4, Loss: 0.6669, Accuracy: 66.76%\n",
      "Epoch 5, Loss: 0.5491, Accuracy: 66.78%\n",
      "Epoch 6, Loss: 0.6158, Accuracy: 66.86%\n",
      "Epoch 7, Loss: 0.5091, Accuracy: 66.75%\n",
      "Epoch 8, Loss: 0.6250, Accuracy: 66.80%\n",
      "Epoch 9, Loss: 0.6921, Accuracy: 66.82%\n",
      "Epoch 10, Loss: 0.5662, Accuracy: 66.80%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.5174, Accuracy: 66.65%\n",
      "Epoch 2, Loss: 0.6986, Accuracy: 66.72%\n",
      "Epoch 3, Loss: 0.9064, Accuracy: 66.75%\n",
      "Epoch 4, Loss: 0.6775, Accuracy: 66.76%\n",
      "Epoch 5, Loss: 0.5842, Accuracy: 66.73%\n",
      "Epoch 6, Loss: 0.6663, Accuracy: 66.68%\n",
      "Epoch 7, Loss: 0.6460, Accuracy: 66.68%\n",
      "Epoch 8, Loss: 0.6034, Accuracy: 66.73%\n",
      "Epoch 9, Loss: 0.7957, Accuracy: 66.60%\n",
      "Epoch 10, Loss: 0.6708, Accuracy: 66.65%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.5523, Accuracy: 67.01%\n",
      "Epoch 2, Loss: 0.7870, Accuracy: 67.03%\n",
      "Epoch 3, Loss: 0.6255, Accuracy: 67.01%\n",
      "Epoch 4, Loss: 0.7194, Accuracy: 67.00%\n",
      "Epoch 5, Loss: 0.5749, Accuracy: 66.98%\n",
      "Epoch 6, Loss: 0.7837, Accuracy: 66.97%\n",
      "Epoch 7, Loss: 0.5534, Accuracy: 67.02%\n",
      "Epoch 8, Loss: 0.7521, Accuracy: 67.08%\n",
      "Epoch 9, Loss: 0.5046, Accuracy: 66.94%\n",
      "Epoch 10, Loss: 0.5988, Accuracy: 67.00%\n",
      "\n",
      "\n",
      "=========== Training round 5 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.6430, Accuracy: 67.01%\n",
      "Epoch 2, Loss: 0.5875, Accuracy: 67.09%\n",
      "Epoch 3, Loss: 0.6678, Accuracy: 66.82%\n",
      "Epoch 4, Loss: 0.5527, Accuracy: 67.05%\n",
      "Epoch 5, Loss: 0.6733, Accuracy: 66.97%\n",
      "Epoch 6, Loss: 0.6501, Accuracy: 67.08%\n",
      "Epoch 7, Loss: 0.6041, Accuracy: 67.08%\n",
      "Epoch 8, Loss: 0.5955, Accuracy: 67.03%\n",
      "Epoch 9, Loss: 0.7508, Accuracy: 67.06%\n",
      "Epoch 10, Loss: 0.6231, Accuracy: 67.02%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.8581, Accuracy: 67.14%\n",
      "Epoch 2, Loss: 0.9358, Accuracy: 67.21%\n",
      "Epoch 3, Loss: 0.7980, Accuracy: 67.16%\n",
      "Epoch 4, Loss: 0.7158, Accuracy: 67.16%\n",
      "Epoch 5, Loss: 0.7633, Accuracy: 67.09%\n",
      "Epoch 6, Loss: 0.6475, Accuracy: 67.24%\n",
      "Epoch 7, Loss: 0.5815, Accuracy: 67.23%\n",
      "Epoch 8, Loss: 0.5991, Accuracy: 67.20%\n",
      "Epoch 9, Loss: 0.6724, Accuracy: 67.17%\n",
      "Epoch 10, Loss: 0.8668, Accuracy: 67.22%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.6312, Accuracy: 66.75%\n",
      "Epoch 2, Loss: 0.6508, Accuracy: 66.85%\n",
      "Epoch 3, Loss: 0.5302, Accuracy: 66.82%\n",
      "Epoch 4, Loss: 0.8499, Accuracy: 66.85%\n",
      "Epoch 5, Loss: 0.6143, Accuracy: 66.85%\n",
      "Epoch 6, Loss: 0.7634, Accuracy: 66.89%\n",
      "Epoch 7, Loss: 0.5361, Accuracy: 66.81%\n",
      "Epoch 8, Loss: 0.7229, Accuracy: 66.74%\n",
      "Epoch 9, Loss: 0.5988, Accuracy: 66.86%\n",
      "Epoch 10, Loss: 0.6514, Accuracy: 66.89%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.5584, Accuracy: 66.71%\n",
      "Epoch 2, Loss: 0.5525, Accuracy: 66.70%\n",
      "Epoch 3, Loss: 0.8696, Accuracy: 66.75%\n",
      "Epoch 4, Loss: 0.7060, Accuracy: 66.74%\n",
      "Epoch 5, Loss: 0.5756, Accuracy: 66.73%\n",
      "Epoch 6, Loss: 0.5768, Accuracy: 66.72%\n",
      "Epoch 7, Loss: 0.6659, Accuracy: 66.75%\n",
      "Epoch 8, Loss: 0.7105, Accuracy: 66.71%\n",
      "Epoch 9, Loss: 0.6515, Accuracy: 66.71%\n",
      "Epoch 10, Loss: 0.5892, Accuracy: 66.78%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.7615, Accuracy: 67.03%\n",
      "Epoch 2, Loss: 0.8234, Accuracy: 67.02%\n",
      "Epoch 3, Loss: 0.6162, Accuracy: 67.00%\n",
      "Epoch 4, Loss: 0.7005, Accuracy: 67.03%\n",
      "Epoch 5, Loss: 0.8000, Accuracy: 67.06%\n",
      "Epoch 6, Loss: 0.7230, Accuracy: 67.04%\n",
      "Epoch 7, Loss: 0.8366, Accuracy: 67.12%\n",
      "Epoch 8, Loss: 0.7213, Accuracy: 67.11%\n",
      "Epoch 9, Loss: 0.6606, Accuracy: 67.11%\n",
      "Epoch 10, Loss: 0.6439, Accuracy: 66.97%\n",
      "\n",
      "\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "def client_training(global_model,train_loader,test_loader):\n",
    "    \n",
    "    local_model = deepcopy(global_model).to(myGPU)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        loss = 0.0\n",
    "        local_model.train()\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(myGPU), data[1].to(myGPU)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        local_model.eval()\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = local_model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, Accuracy: {(correct / total) * 100:.2f}%')\n",
    "    return local_model\n",
    "\n",
    "def model_aggregate(clients_models):\n",
    "    aggregated_state = {}\n",
    "    clients_model_list = []\n",
    "    for models in clients_models:\n",
    "        clients_model_list.append(models.state_dict())\n",
    "        \n",
    "    for key in global_model.state_dict().keys():\n",
    "        tensors_to_aggregate = []\n",
    "        for client_state in clients_model_list:\n",
    "            client_tensor = client_state[key]\n",
    "            tensors_to_aggregate.append(client_tensor)\n",
    "\n",
    "        ### Performing FedAvg ###\n",
    "        stacked_tensors = torch.stack(tensors_to_aggregate, dim=0)\n",
    "        mean_tensor = torch.mean(stacked_tensors, dim=0)\n",
    "\n",
    "        aggregated_state[key] = mean_tensor\n",
    "\n",
    "    # Update the global model's weights with the aggregated weights\n",
    "    global_model.load_state_dict(aggregated_state)\n",
    "    return global_model\n",
    "\n",
    "\n",
    "global_model = Net(30, 4).to(myGPU)\n",
    "\n",
    "total_training_rounds = 5\n",
    "\n",
    "clients_number = 5\n",
    "\n",
    "for i in range(total_training_rounds):\n",
    "    print(f\"=========== Training round {i + 1} ===========\")\n",
    "    clients_models = []\n",
    "    for i in range(clients_number):\n",
    "        print(f\"Training client {i + 1}\")\n",
    "        clients_models.append(client_training(global_model, client_train_dataloader[i],client_test_dataloader[i]))\n",
    "        print(\"\\n\")\n",
    "    # aggregate the models\n",
    "    global_model = model_aggregate(clients_models)\n",
    "\n",
    "print(\"End of training\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:58:43.226985126Z",
     "start_time": "2023-11-30T22:53:22.597376745Z"
    }
   },
   "id": "687181c5234d7322"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performing Federated Training using Label \"Died\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d308644293f6d7c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yche2692/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Training round 1 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.1164, Accuracy: 93.89%\n",
      "Epoch 2, Loss: 0.1018, Accuracy: 93.97%\n",
      "Epoch 3, Loss: 0.0793, Accuracy: 94.05%\n",
      "Epoch 4, Loss: 0.1374, Accuracy: 94.10%\n",
      "Epoch 5, Loss: 0.1199, Accuracy: 94.15%\n",
      "Epoch 6, Loss: 0.1081, Accuracy: 94.18%\n",
      "Epoch 7, Loss: 0.0924, Accuracy: 94.19%\n",
      "Epoch 8, Loss: 0.1831, Accuracy: 94.18%\n",
      "Epoch 9, Loss: 0.3064, Accuracy: 94.19%\n",
      "Epoch 10, Loss: 0.0657, Accuracy: 94.18%\n",
      "\n",
      "\n",
      "Training client 2\n",
      "Epoch 1, Loss: 0.3073, Accuracy: 93.66%\n",
      "Epoch 2, Loss: 0.0643, Accuracy: 93.77%\n",
      "Epoch 3, Loss: 0.1372, Accuracy: 93.82%\n",
      "Epoch 4, Loss: 0.0940, Accuracy: 93.85%\n",
      "Epoch 5, Loss: 0.0814, Accuracy: 93.88%\n",
      "Epoch 6, Loss: 0.0542, Accuracy: 93.91%\n",
      "Epoch 7, Loss: 0.1137, Accuracy: 93.88%\n",
      "Epoch 8, Loss: 0.0166, Accuracy: 93.91%\n",
      "Epoch 9, Loss: 0.1832, Accuracy: 93.85%\n",
      "Epoch 10, Loss: 0.0896, Accuracy: 93.93%\n",
      "\n",
      "\n",
      "Training client 3\n",
      "Epoch 1, Loss: 0.1530, Accuracy: 93.75%\n",
      "Epoch 2, Loss: 0.0299, Accuracy: 93.74%\n",
      "Epoch 3, Loss: 0.2142, Accuracy: 93.91%\n",
      "Epoch 4, Loss: 0.1822, Accuracy: 93.94%\n",
      "Epoch 5, Loss: 0.0614, Accuracy: 93.97%\n",
      "Epoch 6, Loss: 0.1091, Accuracy: 94.01%\n",
      "Epoch 7, Loss: 0.1854, Accuracy: 94.06%\n",
      "Epoch 8, Loss: 0.1069, Accuracy: 94.04%\n",
      "Epoch 9, Loss: 0.0916, Accuracy: 94.05%\n",
      "Epoch 10, Loss: 0.0521, Accuracy: 94.09%\n",
      "\n",
      "\n",
      "Training client 4\n",
      "Epoch 1, Loss: 0.1345, Accuracy: 93.68%\n",
      "Epoch 2, Loss: 0.0989, Accuracy: 93.85%\n",
      "Epoch 3, Loss: 0.1690, Accuracy: 93.86%\n",
      "Epoch 4, Loss: 0.0464, Accuracy: 93.94%\n",
      "Epoch 5, Loss: 0.0663, Accuracy: 93.96%\n",
      "Epoch 6, Loss: 0.2142, Accuracy: 93.89%\n",
      "Epoch 7, Loss: 0.0419, Accuracy: 93.98%\n",
      "Epoch 8, Loss: 0.1366, Accuracy: 94.04%\n",
      "Epoch 9, Loss: 0.1431, Accuracy: 94.03%\n",
      "Epoch 10, Loss: 0.1349, Accuracy: 94.03%\n",
      "\n",
      "\n",
      "Training client 5\n",
      "Epoch 1, Loss: 0.2813, Accuracy: 93.85%\n",
      "Epoch 2, Loss: 0.0997, Accuracy: 93.79%\n",
      "Epoch 3, Loss: 0.1123, Accuracy: 93.85%\n",
      "Epoch 4, Loss: 0.0390, Accuracy: 93.92%\n",
      "Epoch 5, Loss: 0.1342, Accuracy: 93.95%\n",
      "Epoch 6, Loss: 0.1669, Accuracy: 93.94%\n",
      "Epoch 7, Loss: 0.0714, Accuracy: 93.96%\n",
      "Epoch 8, Loss: 0.0851, Accuracy: 93.98%\n",
      "Epoch 9, Loss: 0.1749, Accuracy: 94.03%\n",
      "Epoch 10, Loss: 0.1395, Accuracy: 94.00%\n",
      "\n",
      "\n",
      "=========== Training round 2 ===========\n",
      "Training client 1\n",
      "Epoch 1, Loss: 0.0605, Accuracy: 94.20%\n",
      "Epoch 2, Loss: 0.1818, Accuracy: 94.20%\n",
      "Epoch 3, Loss: 0.0468, Accuracy: 94.09%\n",
      "Epoch 4, Loss: 0.0876, Accuracy: 94.22%\n",
      "Epoch 5, Loss: 0.0435, Accuracy: 94.16%\n"
     ]
    }
   ],
   "source": [
    "myGPU = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def read_data():\n",
    "    # Read the CSV files\n",
    "    df = pd.read_csv('dataset/covid_x_died.csv')\n",
    "    label_df = pd.read_csv('dataset/covid_y_died.csv')\n",
    "\n",
    "    # Sample 10% of the data\n",
    "    df_sampled = df.sample(frac=1, random_state=42)\n",
    "    label_df_sampled = label_df.loc[df_sampled.index]\n",
    "\n",
    "    # Label encoding\n",
    "    encoder = LabelEncoder()\n",
    "    label_df_sampled = encoder.fit_transform(label_df_sampled.values.ravel())\n",
    "\n",
    "    # Concatenate features and labels\n",
    "    combined_df = pd.concat([df_sampled, pd.DataFrame(label_df_sampled, index=df_sampled.index, columns=['Label'])], axis=1)\n",
    "\n",
    "    # Shuffle the combined DataFrame\n",
    "    combined_df_shuffled = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Split the DataFrame into 5 chunks\n",
    "    chunks = np.array_split(combined_df_shuffled, 5)\n",
    "\n",
    "    # Separate features and labels for each chunk\n",
    "    features_chunks = [torch.tensor(chunk.iloc[:, :-1].values, dtype=torch.float32) for chunk in chunks]\n",
    "    labels_chunks = [torch.tensor(chunk.iloc[:, -1].values, dtype=torch.long) for chunk in chunks]\n",
    "\n",
    "    return features_chunks, labels_chunks\n",
    "\n",
    "# Usage\n",
    "X, y = read_data()\n",
    "\n",
    "client_train_dataloader = []\n",
    "client_test_dataloader = []\n",
    "\n",
    "for index in range(len(X)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[index], y[index], test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train.to(myGPU), y_train.to(myGPU))\n",
    "    test_dataset = TensorDataset(X_test.to(myGPU), y_test.to(myGPU))\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
    "    client_train_dataloader.append(train_loader)\n",
    "    client_test_dataloader.append(test_loader)\n",
    "    \n",
    "def client_training(global_model,train_loader,test_loader):\n",
    "    \n",
    "    local_model = deepcopy(global_model).to(myGPU)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        loss = 0.0\n",
    "        local_model.train()\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(myGPU), data[1].to(myGPU)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        local_model.eval()\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = local_model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, Accuracy: {(correct / total) * 100:.2f}%')\n",
    "    return local_model\n",
    "\n",
    "def model_aggregate(clients_models):\n",
    "    aggregated_state = {}\n",
    "    clients_model_list = []\n",
    "    for models in clients_models:\n",
    "        clients_model_list.append(models.state_dict())\n",
    "        \n",
    "    for key in global_model.state_dict().keys():\n",
    "        tensors_to_aggregate = []\n",
    "        for client_state in clients_model_list:\n",
    "            client_tensor = client_state[key]\n",
    "            tensors_to_aggregate.append(client_tensor)\n",
    "\n",
    "        ### Performing FedAvg ###\n",
    "        stacked_tensors = torch.stack(tensors_to_aggregate, dim=0)\n",
    "        mean_tensor = torch.mean(stacked_tensors, dim=0)\n",
    "\n",
    "        aggregated_state[key] = mean_tensor\n",
    "\n",
    "    # Update the global model's weights with the aggregated weights\n",
    "    global_model.load_state_dict(aggregated_state)\n",
    "    return global_model\n",
    "\n",
    "\n",
    "global_model = Net(36, 2).to(myGPU)\n",
    "\n",
    "total_training_rounds = 5\n",
    "\n",
    "clients_number = 5\n",
    "\n",
    "for i in range(total_training_rounds):\n",
    "    print(f\"=========== Training round {i + 1} ===========\")\n",
    "    clients_models = []\n",
    "    for i in range(clients_number):\n",
    "        print(f\"Training client {i + 1}\")\n",
    "        clients_models.append(client_training(global_model, client_train_dataloader[i],client_test_dataloader[i]))\n",
    "        print(\"\\n\")\n",
    "    # aggregate the models\n",
    "    global_model = model_aggregate(clients_models)\n",
    "\n",
    "print(\"End of training\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T23:02:09.342500078Z"
    }
   },
   "id": "8760b7ebbf26fe59"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b68eddea985d24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
